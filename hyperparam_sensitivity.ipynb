{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davidbombara/Documents/discounted-adaptive/env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "File for running all computer vision experiments.\n",
    "\"\"\"\n",
    "import argparse\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import os\n",
    "from re import sub\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, LBFGS, SGD\n",
    "import tqdm\n",
    "\n",
    "# Our new algorithm\n",
    "from online_conformal.magnitude_learner import MagnitudeLearner, MagnitudeLearnerV2\n",
    "from online_conformal.mag_learner_undiscounted import MagLearnUndiscounted\n",
    "from online_conformal.ogd_simple import SimpleOGD\n",
    "\n",
    "# From previous work\n",
    "from online_conformal.saocp import SAOCP\n",
    "from online_conformal.faci import FACI, FACI_S\n",
    "from online_conformal.nex_conformal import NExConformal\n",
    "from online_conformal.ogd import ScaleFreeOGD\n",
    "from online_conformal.split_conformal import SplitConformal\n",
    "from online_conformal.utils import pinball_loss\n",
    "from cv_utils import create_model, data_loader\n",
    "from cv_utils import ImageNet, TinyImageNet, CIFAR10, CIFAR100, ImageNetC, TinyImageNetC, CIFAR10C, CIFAR100C\n",
    "\n",
    "# Import helper functions\n",
    "from vision import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting temp file...\n",
      "Done\n",
      "Load the saved logits\n",
      "Initialize conformal prediction methods, along with accumulators for results\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7050/7050 [00:39<00:00, 179.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution shift: sudden\n",
      "SimpleOGD       :, D_ratio = 0.001  Avg Cov: 0.899, Avg Width: 125.0, LCEk: 0.11,\n",
      "ScaleFreeOGD    :, D_ratio = 0.001  Avg Cov: 0.060, Avg Width: 1.0, LCEk: 0.90,\n",
      "SAOCP           :, D_ratio = 0.001  Avg Cov: 0.392, Avg Width: 25.1, LCEk: 0.87,\n",
      "SplitConformal  :, D_ratio = 0.001  Avg Cov: 0.843, Avg Width: 129.5, LCEk: 0.47,\n",
      "NExConformal    :, D_ratio = 0.001  Avg Cov: 0.892, Avg Width: 123.0, LCEk: 0.14,\n",
      "FACI            :, D_ratio = 0.001  Avg Cov: 0.889, Avg Width: 123.4, LCEk: 0.12,\n",
      "FACI_S          :, D_ratio = 0.001  Avg Cov: 0.892, Avg Width: 124.7, LCEk: 0.11,\n",
      "MagnitudeLearner :, D_ratio = 0.001  Avg Cov: 0.884, Avg Width: 118.5, LCEk: 0.08,\n",
      "MagLearnUndiscounted :, D_ratio = 0.001  Avg Cov: 0.894, Avg Width: 122.1, LCEk: 0.09,\n",
      "MagnitudeLearnerV2 :, D_ratio = 0.001  Avg Cov: 0.888, Avg Width: 122.1, LCEk: 0.07,\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7050/7050 [00:45<00:00, 153.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution shift: sudden\n",
      "SimpleOGD       :, D_ratio = 0.01  Avg Cov: 0.899, Avg Width: 125.0, LCEk: 0.11,\n",
      "ScaleFreeOGD    :, D_ratio = 0.01  Avg Cov: 0.429, Avg Width: 28.0, LCEk: 0.85,\n",
      "SAOCP           :, D_ratio = 0.01  Avg Cov: 0.709, Avg Width: 83.3, LCEk: 0.71,\n",
      "SplitConformal  :, D_ratio = 0.01  Avg Cov: 0.843, Avg Width: 129.5, LCEk: 0.47,\n",
      "NExConformal    :, D_ratio = 0.01  Avg Cov: 0.892, Avg Width: 123.0, LCEk: 0.14,\n",
      "FACI            :, D_ratio = 0.01  Avg Cov: 0.889, Avg Width: 123.4, LCEk: 0.12,\n",
      "FACI_S          :, D_ratio = 0.01  Avg Cov: 0.892, Avg Width: 124.7, LCEk: 0.11,\n",
      "MagnitudeLearner :, D_ratio = 0.01  Avg Cov: 0.884, Avg Width: 118.5, LCEk: 0.08,\n",
      "MagLearnUndiscounted :, D_ratio = 0.01  Avg Cov: 0.894, Avg Width: 122.1, LCEk: 0.09,\n",
      "MagnitudeLearnerV2 :, D_ratio = 0.01  Avg Cov: 0.888, Avg Width: 122.1, LCEk: 0.07,\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7050/7050 [00:40<00:00, 173.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution shift: sudden\n",
      "SimpleOGD       :, D_ratio = 0.1  Avg Cov: 0.899, Avg Width: 125.0, LCEk: 0.11,\n",
      "ScaleFreeOGD    :, D_ratio = 0.1  Avg Cov: 0.891, Avg Width: 137.7, LCEk: 0.39,\n",
      "SAOCP           :, D_ratio = 0.1  Avg Cov: 0.858, Avg Width: 112.6, LCEk: 0.18,\n",
      "SplitConformal  :, D_ratio = 0.1  Avg Cov: 0.843, Avg Width: 129.5, LCEk: 0.47,\n",
      "NExConformal    :, D_ratio = 0.1  Avg Cov: 0.892, Avg Width: 123.0, LCEk: 0.14,\n",
      "FACI            :, D_ratio = 0.1  Avg Cov: 0.889, Avg Width: 123.4, LCEk: 0.12,\n",
      "FACI_S          :, D_ratio = 0.1  Avg Cov: 0.892, Avg Width: 124.7, LCEk: 0.11,\n",
      "MagnitudeLearner :, D_ratio = 0.1  Avg Cov: 0.884, Avg Width: 118.5, LCEk: 0.08,\n",
      "MagLearnUndiscounted :, D_ratio = 0.1  Avg Cov: 0.894, Avg Width: 122.1, LCEk: 0.09,\n",
      "MagnitudeLearnerV2 :, D_ratio = 0.1  Avg Cov: 0.888, Avg Width: 122.1, LCEk: 0.07,\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7050/7050 [00:43<00:00, 160.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution shift: sudden\n",
      "SimpleOGD       :, D_ratio = 1.0  Avg Cov: 0.899, Avg Width: 125.0, LCEk: 0.11,\n",
      "ScaleFreeOGD    :, D_ratio = 1.0  Avg Cov: 0.899, Avg Width: 124.5, LCEk: 0.09,\n",
      "SAOCP           :, D_ratio = 1.0  Avg Cov: 0.883, Avg Width: 119.2, LCEk: 0.10,\n",
      "SplitConformal  :, D_ratio = 1.0  Avg Cov: 0.843, Avg Width: 129.5, LCEk: 0.47,\n",
      "NExConformal    :, D_ratio = 1.0  Avg Cov: 0.892, Avg Width: 123.0, LCEk: 0.14,\n",
      "FACI            :, D_ratio = 1.0  Avg Cov: 0.889, Avg Width: 123.4, LCEk: 0.12,\n",
      "FACI_S          :, D_ratio = 1.0  Avg Cov: 0.892, Avg Width: 124.7, LCEk: 0.11,\n",
      "MagnitudeLearner :, D_ratio = 1.0  Avg Cov: 0.884, Avg Width: 118.5, LCEk: 0.08,\n",
      "MagLearnUndiscounted :, D_ratio = 1.0  Avg Cov: 0.894, Avg Width: 122.1, LCEk: 0.09,\n",
      "MagnitudeLearnerV2 :, D_ratio = 1.0  Avg Cov: 0.888, Avg Width: 122.1, LCEk: 0.07,\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7050/7050 [00:42<00:00, 164.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution shift: sudden\n",
      "SimpleOGD       :, D_ratio = 10.0  Avg Cov: 0.899, Avg Width: 125.0, LCEk: 0.11,\n",
      "ScaleFreeOGD    :, D_ratio = 10.0  Avg Cov: 0.900, Avg Width: 137.6, LCEk: 0.02,\n",
      "SAOCP           :, D_ratio = 10.0  Avg Cov: 0.915, Avg Width: 142.3, LCEk: 0.06,\n",
      "SplitConformal  :, D_ratio = 10.0  Avg Cov: 0.843, Avg Width: 129.5, LCEk: 0.47,\n",
      "NExConformal    :, D_ratio = 10.0  Avg Cov: 0.892, Avg Width: 123.0, LCEk: 0.14,\n",
      "FACI            :, D_ratio = 10.0  Avg Cov: 0.889, Avg Width: 123.4, LCEk: 0.12,\n",
      "FACI_S          :, D_ratio = 10.0  Avg Cov: 0.892, Avg Width: 124.7, LCEk: 0.11,\n",
      "MagnitudeLearner :, D_ratio = 10.0  Avg Cov: 0.884, Avg Width: 118.5, LCEk: 0.08,\n",
      "MagLearnUndiscounted :, D_ratio = 10.0  Avg Cov: 0.894, Avg Width: 122.1, LCEk: 0.09,\n",
      "MagnitudeLearnerV2 :, D_ratio = 10.0  Avg Cov: 0.888, Avg Width: 122.1, LCEk: 0.07,\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7050/7050 [00:43<00:00, 162.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution shift: sudden\n",
      "SimpleOGD       :, D_ratio = 100.0  Avg Cov: 0.899, Avg Width: 125.0, LCEk: 0.11,\n",
      "ScaleFreeOGD    :, D_ratio = 100.0  Avg Cov: 0.900, Avg Width: 168.0, LCEk: 0.00,\n",
      "SAOCP           :, D_ratio = 100.0  Avg Cov: 0.954, Avg Width: 183.8, LCEk: 0.10,\n",
      "SplitConformal  :, D_ratio = 100.0  Avg Cov: 0.843, Avg Width: 129.5, LCEk: 0.47,\n",
      "NExConformal    :, D_ratio = 100.0  Avg Cov: 0.892, Avg Width: 123.0, LCEk: 0.14,\n",
      "FACI            :, D_ratio = 100.0  Avg Cov: 0.889, Avg Width: 123.4, LCEk: 0.12,\n",
      "FACI_S          :, D_ratio = 100.0  Avg Cov: 0.892, Avg Width: 124.7, LCEk: 0.11,\n",
      "MagnitudeLearner :, D_ratio = 100.0  Avg Cov: 0.884, Avg Width: 118.5, LCEk: 0.08,\n",
      "MagLearnUndiscounted :, D_ratio = 100.0  Avg Cov: 0.894, Avg Width: 122.1, LCEk: 0.09,\n",
      "MagnitudeLearnerV2 :, D_ratio = 100.0  Avg Cov: 0.888, Avg Width: 122.1, LCEk: 0.07,\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7050/7050 [00:40<00:00, 172.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution shift: sudden\n",
      "SimpleOGD       :, D_ratio = 100.0  Avg Cov: 0.899, Avg Width: 125.0, LCEk: 0.11,\n",
      "ScaleFreeOGD    :, D_ratio = 100.0  Avg Cov: 0.900, Avg Width: 168.0, LCEk: 0.00,\n",
      "SAOCP           :, D_ratio = 100.0  Avg Cov: 0.954, Avg Width: 183.8, LCEk: 0.10,\n",
      "SplitConformal  :, D_ratio = 100.0  Avg Cov: 0.843, Avg Width: 129.5, LCEk: 0.47,\n",
      "NExConformal    :, D_ratio = 100.0  Avg Cov: 0.892, Avg Width: 123.0, LCEk: 0.14,\n",
      "FACI            :, D_ratio = 100.0  Avg Cov: 0.889, Avg Width: 123.4, LCEk: 0.12,\n",
      "FACI_S          :, D_ratio = 100.0  Avg Cov: 0.892, Avg Width: 124.7, LCEk: 0.11,\n",
      "MagnitudeLearner :, D_ratio = 100.0  Avg Cov: 0.884, Avg Width: 118.5, LCEk: 0.08,\n",
      "MagLearnUndiscounted :, D_ratio = 100.0  Avg Cov: 0.894, Avg Width: 122.1, LCEk: 0.09,\n",
      "MagnitudeLearnerV2 :, D_ratio = 100.0  Avg Cov: 0.888, Avg Width: 122.1, LCEk: 0.07,\n"
     ]
    }
   ],
   "source": [
    "args = parse_args()\n",
    "if not finished(args) and args.dataset != \"ImageNet\":\n",
    "    print(\"Training models\")\n",
    "    train(args)\n",
    "    print(\"Finished training\")\n",
    "if args.local_rank in [-1, 0]:\n",
    "    print(\"Getting temp file...\")\n",
    "    temp_file = get_temp_file(args)\n",
    "    print(\"Done\")\n",
    "    if not finished(args):\n",
    "        print(\"get_logits(args)\")\n",
    "        get_logits(args)\n",
    "        print(\"...Done\")\n",
    "        temp = temperature_scaling(args)\n",
    "        with open(temp_file, \"w\") as f:\n",
    "            f.write(str(temp))\n",
    "\n",
    "    # Load the saved logits\n",
    "    print(\"Load the saved logits\")\n",
    "    with open(temp_file) as f:\n",
    "        temp = float(f.readline())\n",
    "    n_data = None\n",
    "    sev2results = defaultdict(list)\n",
    "    for corruption in corruptions:\n",
    "        severities = [0] if corruption is None else [1, 2, 3, 4, 5]\n",
    "        for severity in severities:\n",
    "            try:\n",
    "                logits, labels = torch.load(get_results_file(args, corruption, severity))\n",
    "            except:\n",
    "                continue\n",
    "            sev2results[severity].append(list(zip(F.softmax(logits / temp, dim=-1).numpy(), labels.numpy())))\n",
    "            n_data = len(labels) if n_data is None else min(n_data, len(labels))\n",
    "\n",
    "    # Initialize conformal prediction methods, along with accumulators for results\n",
    "    print(\"Initialize conformal prediction methods, along with accumulators for results\")\n",
    "    lmbda, k_reg, n_class = raps_params(args.dataset)\n",
    "    D_true = 1 + lmbda * np.sqrt(n_class - k_reg)\n",
    "    D_list = np.array([1e-3, 1e-2, 1e-1, 1, 10, 100, 100])*D_true\n",
    "    #methods = [SimpleOGD, MagnitudeLearner, MagLearnUndiscounted, MagnitudeLearnerV2]\n",
    "    methods = [SimpleOGD, ScaleFreeOGD, SAOCP, SplitConformal, NExConformal, FACI, FACI_S, MagnitudeLearner, MagLearnUndiscounted, MagnitudeLearnerV2]\n",
    "        \n",
    "    avg_cov = np.zeros((len(D_list), len(methods)))\n",
    "    avg_width = np.zeros_like(avg_cov)\n",
    "    lce_k = np.zeros_like(avg_cov)\n",
    "\n",
    "    for i_D in range(len(D_list)):\n",
    "        D = D_list[i_D]\n",
    "        label2err = defaultdict(list)\n",
    "        h = 5 + 0.5 * (len(methods) > 5)\n",
    "        np.random.seed(0)\n",
    "        for i_shift, shift in enumerate([\"sudden\"]):\n",
    "            \n",
    "            sevs, s_opts, w_opts = [], [], []\n",
    "            # warmup, window, run_length = 1000, 100, 500 # original code\n",
    "            warmup, window, run_length = 1000, 100, 1000 # our code\n",
    "            state = np.random.RandomState(0)\n",
    "            order = state.permutation(n_data)[: 6 * run_length + window // 2 + warmup]\n",
    "            coverages, s_hats, widths = [{m.__name__: [] for m in methods} for _ in range(3)]\n",
    "            predictors = [m(None, None, max_scale = D, lifetime = 32, coverage = args.target_cov) for m in methods]\n",
    "            t_vec = np.zeros(len(order))\n",
    "            for t, i in tqdm.tqdm(enumerate(order, start=-warmup), total=len(order)):\n",
    "                sev = t_to_sev(t, window=window, schedule = shift)\n",
    "                probs, label = sev2results[sev][state.randint(0, len(sev2results[sev]))][i]\n",
    "\n",
    "                # Convert probability to APS score\n",
    "                i_sort = np.flip(np.argsort(probs))\n",
    "                p_sort_cumsum = np.cumsum(probs[i_sort]) - state.rand() * probs[i_sort]\n",
    "                s_sort_cumsum = p_sort_cumsum + lmbda * np.sqrt(np.cumsum([i > k_reg for i in range(n_class)]))\n",
    "                w_opt = np.argsort(i_sort)[label] + 1\n",
    "                s_opt = s_sort_cumsum[w_opt - 1]\n",
    "                if t >= 0:\n",
    "                    sevs.append(sev)\n",
    "                    s_opts.append(s_opt)\n",
    "                    w_opts.append(w_opt)\n",
    "                    t_vec[t] = t\n",
    "\n",
    "                # Update all the conformal predictors\n",
    "                for predictor in predictors:\n",
    "                    name = type(predictor).__name__\n",
    "                    if t >= 0:\n",
    "                        _, s_hat = predictor.predict(horizon=1)\n",
    "                        w = np.sum(s_sort_cumsum <= s_hat)\n",
    "                        s_hats[name].append(s_hat)\n",
    "                        widths[name].append(w)\n",
    "                        coverages[name].append(w >= w_opt)\n",
    "                    predictor.update(ground_truth=pd.Series([s_opt]), forecast=pd.Series([0]), horizon=1)\n",
    "\n",
    "            plot_loss = False\n",
    "            sevs = pd.Series(sevs).rolling(window).mean().dropna()\n",
    "            w_opts = pd.Series(s_opts if plot_loss else w_opts).rolling(window).quantile(args.target_cov).dropna()\n",
    "\n",
    "            s_opts = np.asarray(s_opts)\n",
    "            int_q = pd.Series(s_opts).rolling(window).quantile(args.target_cov).dropna()\n",
    "            print(f\"Distribution shift: {shift}\")\n",
    "            for i, m in enumerate(methods):\n",
    "                # Compute various summary statistics\n",
    "                name = m.__name__ # name of the method (OGD, SAOCP, etc.)\n",
    "                label = sub(\"Split\", \"S\", sub(\"Conformal\", \"CP\", sub(\"ScaleFree\", \"SF-\", sub(\"_\", \"-\", name))))\n",
    "                if name == \"MagnitudeLearner\":\n",
    "                    #label = \"Mag. Learner ($\\lambda_t < 1$)\"\n",
    "                    label = \"MagL-D\"\n",
    "                if name == \"MagLearnUndiscounted\":\n",
    "                    #label = \"Mag. Learner ($\\lambda_t = 1$)\"\n",
    "                    label = \"MagL\"\n",
    "                if name == \"MagnitudeLearnerV2\":\n",
    "                    #label = \"Mag. Learner ($\\lambda_t < 1, h_t = 0$)\"\n",
    "                    label = \"MagDis\"\n",
    "                s_hat = np.asarray(s_hats[name])\n",
    "                int_cov = gaussian_filter1d(pd.Series(coverages[name]).rolling(window).mean().dropna(), sigma=3)\n",
    "                int_w = pd.Series(s_hats[name] if plot_loss else widths[name]).rolling(window).mean().dropna()\n",
    "                int_losses = pd.Series(pinball_loss(s_opts, s_hat, args.target_cov)).rolling(window).mean().dropna()\n",
    "                opts = [pinball_loss(s_opts[i : i + window], q, args.target_cov).mean() for i, q in enumerate(int_q)]\n",
    "                int_regret = int_losses.values - np.asarray(opts)\n",
    "                int_miscov = np.abs(args.target_cov - int_cov)\n",
    "\n",
    "                # Average values for plotting\n",
    "                avg_cov[i_D, i] = np.mean(coverages[name])\n",
    "                avg_width[i_D, i] = np.mean(widths[name])\n",
    "                lce_k[i_D, i] = np.max(int_miscov)\n",
    "                #\n",
    "                print(\n",
    "                    f\"{name:15} :, \"\n",
    "                    f\"D_ratio = {D/D_true} \",\n",
    "                    f\"Avg Cov: {avg_cov[i_D,i]:.3f}, \"\n",
    "                    f\"Avg Width: {avg_width[i_D,i]:.1f}, \"\n",
    "                    f\"LCEk: {lce_k[i_D,i]:.2f},\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results\n",
    "np.savez_compressed('hyperparam_results.npz',methods=methods,D_list=D_list,avg_cov=avg_cov, avg_width=avg_width, lce_k=lce_k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
